{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5667ec55-3a2e-4730-a4a9-415d6971ed08",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Self-Attention With Trainable Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ef1992-ec28-4b27-b7cd-eacd00e0137e",
   "metadata": {},
   "source": [
    "To implement the self-attention mechanisme, we would need to introduce the trainable weight matrices\n",
    "Wq, Wk and Wv\n",
    "These three matrices are used to project the embedded input tokens into query, key and value vectors respectively /\n",
    "In the first step of the self-attention mechanism with traninable weights, we compute:\n",
    "* query (q)\n",
    "* key (k)\n",
    "* value (v) \\\n",
    "for the input elements x \\\n",
    "\n",
    "We designate the second input x2 as the query input\n",
    "* the query vector is obtained by matrix multiplication between the input and the weight matrix Wq\n",
    "* the key vector is obtained by matrix multiplication between the input and the weight matrix Wk\n",
    "* the value vector is obtained by a matriv multiplication between the input and weight matrix Wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b98283a-baa0-4c01-9532-b243ff4ddbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\administrator\\pycharmprojects\\llm-tutorial\\.venv\\lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:258: UserWarning: Failed to initialize NumPy: numpy.core.multiarray failed to import (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#initialize the inputs\n",
    "inputs = torch.tensor(\n",
    "    [\n",
    "        [0.43, 0.15, 0.89], # Your    (x^1)\n",
    "        [0.55, 0.87, 0.66], # journey (x^2)\n",
    "        [0.57, 0.85, 0.64], # starts  \n",
    "        [0.22, 0.58, 0.33], # with\n",
    "        [0.77, 0.25, 0.01], # one\n",
    "        [0.05, 0.80, 0.55]  #step\n",
    "    ]\n",
    ")\n",
    "\n",
    "x_2 = inputs[1] #the second element of the inputs\n",
    "d_in = inputs.shape[1] # the size of the input embedding, d=3\n",
    "d_out = 2 # the output embedding size, d_out=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98471852-0aad-4c58-a570-a88c0e1dcf87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5500, 0.8700, 0.6600])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "454e2d1b-fb27-4b94-b82e-be7713bb9496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the weight matrices\n",
    "torch.manual_seed(123)\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_key = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "# Note that we set the requires_grad parameter to False, but if we would use the weight matrices for training, we set to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3495f4a6-7a6f-4781-90ac-3ece1c25a4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.1366, 0.1025],\n",
       "        [0.1841, 0.7264],\n",
       "        [0.3153, 0.6871]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e371dcc-fdb5-4ab0-83f3-d7735d8fda51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now comput the query, key and value vectors\n",
    "query_2 = x_2 @ W_query\n",
    "key_2 = x_2 @ W_key\n",
    "value_2 = x_2 @ W_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7681660-eabd-457c-ad76-7a99e8287c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4306, 1.4551])\n",
      "tensor([0.4433, 1.1419])\n",
      "tensor(1.8524)\n"
     ]
    }
   ],
   "source": [
    "print(query_2)\n",
    "print(key_2)\n",
    "score_2 = query_2.dot(key_2)\n",
    "print(score_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9aa47d-8977-4d78-8265-c915dc894d2e",
   "metadata": {},
   "source": [
    "## Weight Parameters vs Attention Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36313576-e960-47e4-a47b-9fc1717fa621",
   "metadata": {},
   "source": [
    "The weight matrices here is not the same as the attention weights.\n",
    "The weight parameters of a network are the values that are optimized during the training phase\n",
    "Attention weights are the values that determine the extent to which the context vector depends on other parts of the input \\\n",
    "Weight parameters are teh fundamental learnt coefficients that define the network structur while attention weights are\n",
    "dynamic context-specific values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be984c1c-c37f-42db-8719-9baabca5117d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys.shape: torch.Size([6, 2])\n",
      "values.shape: torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "# Obtain all keys and values\n",
    "keys = inputs @ W_key\n",
    "values = inputs @ W_value\n",
    "print(\"keys.shape:\", keys.shape)\n",
    "print(\"values.shape:\", values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecea9ef1-40b5-4a52-9cc5-9a1bc13e2133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3669, 0.7646],\n",
       "        [0.4433, 1.1419],\n",
       "        [0.4361, 1.1156],\n",
       "        [0.2408, 0.6706],\n",
       "        [0.1543, 0.2674],\n",
       "        [0.3275, 0.9642]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ff19dac-9640-4dbc-80fd-3657cb5ec3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4433, 1.1419])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys_2 = keys[1]\n",
    "keys_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8524254-53e8-465a-9e06-b314f0c3392f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8524)\n"
     ]
    }
   ],
   "source": [
    "# Compute the attention scores for input 2 against keys_2\n",
    "attn_score_22 = query_2.dot(keys_2)\n",
    "print(attn_score_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f3abfa9-6a10-46f3-b03d-021c5dfb17c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.4555, 1.5440])\n"
     ]
    }
   ],
   "source": [
    "# Compute the attention scores for the given query\n",
    "attention_scores_2 = query_2 @ keys.T\n",
    "print(attention_scores_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf066f1e-293d-4025-b608-14f7eaafd2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1510, 0.2278, 0.2213, 0.1319, 0.0848, 0.1832])\n"
     ]
    }
   ],
   "source": [
    "# We now need to calculate the attention weights\n",
    "# this is done by scaling the attention scores by dividing them by the square root of the embedding dimention of the keys\n",
    "\n",
    "d_k = keys.shape[-1] # calculate the size of the last dimension of the keys tensor\n",
    "attn_weight_2 = torch.softmax(attention_scores_2/ d_k**0.5, dim=-1) # dk**0.5 is the scaling factor and used to stabilize the softmax computation\n",
    "print(attn_weight_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82db28e0-704c-4eae-9cfb-599afe15fb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3062, 0.8178])\n"
     ]
    }
   ],
   "source": [
    "# Compute the context vector by combining all value vectors via the attention weights\n",
    "context_vec_2 = attn_weight_2 @ values\n",
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2cd3552-3c3f-4311-96b7-c2a898d1cc4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2993, 0.8003],\n",
       "        [0.3062, 0.8178],\n",
       "        [0.3059, 0.8170],\n",
       "        [0.2942, 0.7874],\n",
       "        [0.2906, 0.7782],\n",
       "        [0.2987, 0.7989]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assignment: Compute all context vectors\n",
    "context_vectors = torch.empty(inputs.size(0), W_value.size(1))\n",
    "for index, item in enumerate(inputs):\n",
    "    # compute the query\n",
    "    query = item @ W_query\n",
    "    key = inputs @ W_key\n",
    "    value = inputs @ W_value\n",
    "\n",
    "    # compute the attention scores across the keys\n",
    "    attention_scores = query @ key.T\n",
    "\n",
    "    # calculate the attention weight\n",
    "    key_dim = key.shape[-1]\n",
    "    attention_weights = torch.softmax(attention_scores/key_dim**0.5, dim=-1)\n",
    "\n",
    "    # compute the context vector\n",
    "    context_vector = attention_weights @ value\n",
    "\n",
    "    # add the computed context vector to postion index of the context_vectors\n",
    "    context_vectors[index] = context_vector\n",
    "\n",
    "context_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5591116-f490-4b2f-a639-9b09ae8fa7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2993, 0.8003],\n",
      "        [0.3062, 0.8178],\n",
      "        [0.3059, 0.8170],\n",
      "        [0.2942, 0.7874],\n",
      "        [0.2906, 0.7782],\n",
      "        [0.2987, 0.7989]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Using our concise self-attention class\n",
    "import torch\n",
    "from utilities.SelfAttention import SelfAttention_v1\n",
    "torch.manual_seed(123)\n",
    "sa_v1 = SelfAttention_v1(d_in, d_out)\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1636cc5c-7872-410d-95b4-591f74c3e902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5308, -0.1104],\n",
      "        [-0.5293, -0.1133],\n",
      "        [-0.5293, -0.1133],\n",
      "        [-0.5266, -0.1131],\n",
      "        [-0.5275, -0.1122],\n",
      "        [-0.5268, -0.1136]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Using the improved self-attention class\n",
    "from utilities.SelfAttention import SelfAttention_v2\n",
    "torch.manual_seed(789)\n",
    "sa_v2 = SelfAttention_v2(d_in, d_out)\n",
    "print(sa_v2(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3466026f-1d75-4b2e-b3ef-a25514a380cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
